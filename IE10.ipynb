{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGcLrJhZuzvFC5sM4JDpn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-Yadav73/Image-Enhancement/blob/main/IE10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq9-ecPKHR20"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1U8l3AxtlbL"
      },
      "source": [
        "# MOUNTING THE GOOGLE DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QKN7WyB3-2YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhDQ_bkYKa_q"
      },
      "source": [
        "# IMAGE GENERATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfZQxLzbKjup"
      },
      "source": [
        "**Image generation involves creating new images from scratch or based on existing images using techniques such as generative adversarial networks (GANs). This can be used in applications like creating realistic human faces or artistic images.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bW7Zsd0Llko"
      },
      "source": [
        "*Generative Adversarial Networks (GANs)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI4J1n1oLoEM"
      },
      "source": [
        "**A GAN consists of two parts:\n",
        "\n",
        "A generator that tries to create realistic images.\n",
        "A discriminator that tries to distinguish between real and generated images.\n",
        "The generator and discriminator are trained together in a process where the generator improves at creating images that fool the discriminator.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkVE_pnkSi2P"
      },
      "source": [
        "# COLOUR DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl1xygekSy-d"
      },
      "source": [
        "**Color detection involves identifying and segmenting objects based on their color properties. Techniques such as color thresholding and color histograms are used to analyze the color distribution and extract relevant features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0U0v8pdUGgQ"
      },
      "source": [
        "*HSV IMAGE*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tjAIjcAUKtc"
      },
      "source": [
        "An HSV image is an image that uses the HSV (hue, saturation, value) color model to represent colors:\n",
        "\n",
        "**Hue**\n",
        "\n",
        "The angle of a color on the RGB color circle, measured in degrees from 0 to 360. For example, red is at 0°, green is at 120°, and blue is at 240°.\n",
        "\n",
        "**Saturation**\n",
        "\n",
        "The amount of color used, ranging from 0% (grayscale) to 100% (fully saturated).\n",
        "\n",
        "**Value**\n",
        "\n",
        "The brightness of the color, ranging from 0% (black) to 100% (full brightness)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2OKu_u82S14r"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/images.jpeg\")\n",
        "print(\"ORGINAL IMAGE\")\n",
        "cv2_imshow(image)\n",
        "hsv_image=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
        "print(\"HSV IMAGE\")\n",
        "cv2_imshow(hsv_image)\n",
        "lower_red=np.array([0,50,50])\n",
        "upper_red=np.array([10,255,255])\n",
        "mask=cv2.inRange(hsv_image,lower_red,upper_red)\n",
        "print(\"MASKED IMAGE\")\n",
        "cv2_imshow(mask)\n",
        "res=cv2.bitwise_and(image,image,mask=mask)\n",
        "print(\"RESULTANT IMAGE\")\n",
        "cv2_imshow(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Q1DnjzV7R9"
      },
      "source": [
        "# PATTERN RECOGNITION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUuMwb03WNAU"
      },
      "source": [
        "**Pattern recognition is the process of classifying input data into objects or classes based on key features. Techniques such as neural networks, support vector machines, and template matching are used to recognize patterns and make classifications.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qGhpgsBWUv1"
      },
      "source": [
        "*TEMPLATE MATCHING*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsn0eLV5WYuA"
      },
      "source": [
        "**Template matching is one of the simplest methods for recognizing a pattern or template within a larger image.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rgbT0TFCWJap"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/360_F_526700862_DoCU6keWoDHkxyPutkSSmBzKia5eWSTZ.jpg\")\n",
        "print(\"ORGINAL IMAGE\")\n",
        "cv2_imshow(image)\n",
        "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "print(\"GRAY IMAGE\")\n",
        "cv2_imshow(gray_image)\n",
        "template=cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/360_F_526700862_DoCU6keWoDHkxyPutkSSmBzKia5eWSTZ.jpg\",0)\n",
        "print(\"TEMPLATE IMAGE\")\n",
        "cv2_imshow(template)\n",
        "w,h=template.shape[::-1]\n",
        "res=cv2.matchTemplate(gray_image,template,cv2.TM_CCOEFF_NORMED)\n",
        "threshold=0.8\n",
        "loc=np.where(res>=threshold)\n",
        "for pt in zip(*loc[::-1]):\n",
        "  cv2.rectangle(image,pt,(pt[0]+w,pt[1]+h),(0,255,255),2)\n",
        "print(\"RESULTANT IMAGE\")\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CydD_dTOZNQ6"
      },
      "source": [
        " *Feature Matching*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wnAN7NIZSes"
      },
      "source": [
        "**Feature-based methods are used to recognize patterns even when they are rotated, scaled, or translated. These methods focus on finding distinctive points (features) in an image and matching these points across images. Examples of feature-based methods include SIFT, SURF, and ORB.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o8neRKVmZz0M"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/2_70cb0e7d-22aa-4df7-8456-0fdf7b709476.webp\")\n",
        "print(\"ORGINAL IMAGE\")\n",
        "cv2_imshow(image)\n",
        "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "print(\"GRAY IMAGE\")\n",
        "cv2_imshow(gray_image)\n",
        "sift=cv2.SIFT_create()\n",
        "keypoints,descriptors=sift.detectAndCompute(gray_image,None)\n",
        "image_with_keypoints=cv2.drawKeypoints(image,keypoints,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "print(\"IMAGE WITH KEYPOINTS\")\n",
        "cv2_imshow(image_with_keypoints)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCNTXGkVaayJ"
      },
      "source": [
        "*Machine Learning-Based Pattern Recognition*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEfQAgl9adFi"
      },
      "source": [
        "**Support Vector Machines are supervised learning models that are typically used for classification tasks. In pattern recognition, SVMs can be used to classify images or parts of images based on feature extraction techniques.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sIRSnIltah61"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/2_70cb0e7d-22aa-4df7-8456-0fdf7b709476.webp\")\n",
        "print(\"ORGINAL IMAGE\")\n",
        "cv2_imshow(image)\n",
        "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "print(\"GRAY IMAGE\")\n",
        "cv2_imshow(gray_image)\n",
        "sift=cv2.SIFT_create()\n",
        "keypoints,descriptors=sift.detectAndCompute(gray_image,None)\n",
        "image_with_keypoints=cv2.drawKeypoints(image,keypoints,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "print(\"IMAGE WITH KEYPOINTS\")\n",
        "cv2_imshow(image_with_keypoints)\n"
      ]
    }
  ]
}